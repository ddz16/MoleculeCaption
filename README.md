# MoleculeCaption
 This repository contains the code of the downstream task (molecule caption) in the paper "Natural Language-informed Understanding of Molecule Graphsâ€



# Environment

The requirements for the evaluation code conda environment are in environment_eval.yml. An environment can be created using the following commands:

```
conda env create -n MoleculeCaption -f environment_eval.yml python=3.9
conda activate MoleculeCaption
python -m spacy download en_core_web_sm
pip install git+https://github.com/samoturk/mol2vec
```
After running above commands, we can get the environment:
```
python 3.9.12
torch: 1.11.0
cuda: 11.3
```
Then we can install following packages:
```
# torch_geometric 
# you can download the following *.whl files in https://data.pyg.org/whl/
pip install https://data.pyg.org/whl/torch-1.11.0%2Bcu113/pyg_lib-0.1.0%2Bpt111cu113-cp39-cp39-linux_x86_64.whl
pip install https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_cluster-1.6.0-cp39-cp39-linux_x86_64.whl
pip install https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_scatter-2.0.9-cp39-cp39-linux_x86_64.whl
pip install https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_sparse-0.6.13-cp39-cp39-linux_x86_64.whl
pip install torch-geometric

# rdkit and ogb
pip install rdkit-pypi
pip install ogb
pip install sentencepiece
```

# MolT5 & SciBert Checkpoints

Before jointly training the MolT5 model and GIN model in the molecule caption task, you should download three MolT5 checkpoints with different sizes on [huggingface](https://huggingface.co/laituan245). You can directly run following commands:
```
# download MolT5 checkpoints
git lfs clone https://huggingface.co/laituan245/molt5-small-smiles2caption
git lfs clone https://huggingface.co/laituan245/molt5-base-smiles2caption
git lfs clone https://huggingface.co/laituan245/molt5-large-smiles2caption
```

After downloading, put them into three folders `molt5-small-smiles2caption/`, `molt5-base-smiles2caption/`, `molt5-large-smiles2caption/`, respectively. The final directory should look like this:

```
--molt5-small/base/large-smiles2caption
  --config.json
  --pytorch_model.bin
  --README.md
  --special_tokens_map.json
  --spiece.model
  --tokenizer.json
  --tokenizer_config.json
```

You should also download the SciBert checkpoint on [huggingface](https://huggingface.co/allenai/scibert_scivocab_uncased). After downloading, put them into the `scibert/` folder. The final directory should look like this:

```
--scibert
  --config.json
  --flax_model.msgpack
  --pytorch_model.bin
  --vocab.txt
```

# Our Pretrained models

To better utilize the structural information of the input molecule for translation, we append the graph feature of the molecular graph to the inputs of the MolT5 encoder through a feature mapping module, which is implemented by a multi-layer perceptron. The graph features are extracted by the graph encoder GIN in MoMu-K or MoMu-S. You can download them on [the Baidu Netdisk](https://pan.baidu.com/s/1jvMP_ysQGTMd_2sTLUD45A), the password is **1234**. 

MoMu-K checkpoint:

```
checkpoints/littlegin=graphclinit_bert=kvplm_epoch=299-step=18300.ckpt
```

MoMu-S checkpoint:

```
checkpoints/littlegin=graphclinit_bert=scibert_epoch=299-step=18300.ckpt
```

After downloading, you should put these two checkpoints into the `MoMu_checkpoints/` folder.

# Evaluation
We provide two output files generated by **MoMu-S**-enhanced MolT5 of different sizes. `out_small.txt` is generated by **MoMu-S**-enhanced MolT5-small, `out_base.txt` is generated by **MoMu-S**-enhanced MolT5-base. So you can evaluate the performance without running the finetune & generate captions commands. To evaluate the molecule caption task, you can directly use these output files generated by MoMu-enhanced MolT5. Detailed evaluation commands are as follows.

## The BLEU & Rouge & Meteor metrics

Before evaluating the NLG metrics, you should download packages wordnet and omw-1.4:
```
python
>>> import nltk
>>> nltk.download('wordnet')
>>> nltk.download('omw-1.4')
```

Then, run these commands to evaluate all NLG metrics for different model sizes:
```
python text_translation_metrics.py --input_file out_small.txt
# BLEU-2 score: 0.5324291460271013
# BLEU-4 score: 0.4456614250078922
# Average Meteor score: 0.5582335314659328
# ROUGE score:
# rouge1: 0.6216177742805807
# rouge2: 0.46989204033857784
# rougeL: 0.5642962657194562

python text_translation_metrics.py --input_file out_base.txt
# BLEU-2 score: 0.5509759199437636
# BLEU-4 score: 0.46462751630139193
# Average Meteor score: 0.5748233411951438
# ROUGE score:
# rouge1: 0.6342144165700273
# rouge2: 0.48534549361001156
# rougeL: 0.5770352392556646

```

## The Text2Mol metric
Before evaluating the Text2Mol metric, download the `cids_to_smiles.pkl` file from https://uofi.box.com/v/MolT5-cid-to-smiles and `test_outputfinal_weights.320.pt` form https://uofi.box.com/s/es16alnhzfy1hpagf55fu48k49f8n29x. `cids_to_smiles.pkl` should be placed in the root path of the project and `test_outputfinal_weights.320.pt` should be placed in the `t2m_output/` folder. Then run these commands:

```
python text_text2mol_metric.py --input_file out_small.txt
# 0.5426342

python text_text2mol_metric.py --input_file out_base.txt
# 0.54901445

```

# Finetune & Generate captions
We provide finetuned checkpoints of **MoMu-S-enhanced MolT5** with two different sizes (small/base). If you want to generate captions without finetuning, you can download the two checkpoints from , the password is **1234**. Put these three checkpoints in `./saved_models` folder, you can skip the finetuning process and directly run the commands for generating captions.

## Finetune
Finetune **MoMu-S**-enhanced MolT5:
```
# MoMu-S-enhanced MolT5-small/base/large
python main_transformer_smiles2caption.py --mode train --model_size small/base/large
```

or finetune **MoMu-K**-enhanced MolT5:
```
# MoMu-K-enhanced MolT5-small/base/large
python main_transformer_smiles2caption.py --mode train --model_size small/base/large --MoMuK
```

## Generate captions
After finetuning, you can generate the captions of all the molecules in the test dataset. For example, run these commands for MoMu-enhanced MolT5-base model:

```
# MoMu-S-enhanced MolT5-base
python main_transformer_smiles2caption.py --mode test --model_size base --output_file out_base.txt
# MoMu-K-enhanced MolT5-base
python main_transformer_smiles2caption.py --mode test --model_size base --output_file out_base.txt --MoMuK
```

A file `out_base.txt` will be generated. It contains all the SMILES strings, caption ground truths and captions generated by MoMu-enhanced MolT5-base, just like:
```
SMILES	ground truth	output
CCCCCCCCCCCCCCCCCCCCCC[C@H](C(=O)N[C@@H](CO[C@H]1[C@@H]([C@H]([C@H]([C@H](O1)CO)O)OS(=O)(=O)O)O)[C@@H](/C=C/CCCCCCCCCCCCC)O)O	The molecule is a galactosylceramide sulfate in which the sulfo group is located at position 3 and the ceramide N-acyl group is specified as (R)-2-hydroxylignoceroyl. It is a N-acyl-beta-D-galactosylsphingosine and a galactosylceramide sulfate. It derives from a (R)-2-hydroxylignoceric acid. It is a conjugate acid of a 1-(3-O-sulfo-beta-D-galactosyl)-N-[(2R)-2-hydroxylignoceroyl]sphingosine(1-).	The molecule is a galactosylceramide sulfate in which the ceramide N-acyl group is specified as (R)-2-hydroxybehenoyl. It is a galactosylceramide sulfate and a N-acyl-beta-D-galactosylsphingosine. It is a conjugate acid of a 1-(3-O-sulfo-beta-D-galactosyl)-N-[(2R)-2-hydroxybehenoyl]sphingosine(1-).
...
...
```


# Acknowledgment

We adapted the code of the PyTorch implementation of [MolT5](https://github.com/blender-nlp/MolT5/tree/main/evaluation). Thanks to the original authors for their work!

# Citation

```
@article{su2022molecular,
  title={Natural Language-informed Understanding of Molecule Graphs},
  author={Bing Su, Dazhao Du, Zhao Yang, Yujie Zhou, Jiangmeng Li, Anyi Rao, Hao Sun, Zhiwu Lu, Ji-Rong Wen},
  year={2022}
}
```